{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk2743/just-verdict/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/pk2743/just-verdict/env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from semantic_roberta import get_similarity_scores_triples, get_topk_similar_evidences\n",
    "from textual_entailment import get_entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle('./data/dev_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       claim_kg_size  main_text_kg_size\n",
      "count    2452.000000        2452.000000\n",
      "mean        3.113785          23.469005\n",
      "std         0.534892          15.511103\n",
      "min         1.000000           2.000000\n",
      "25%         3.000000          13.000000\n",
      "50%         3.000000          21.000000\n",
      "75%         3.000000          30.000000\n",
      "max         9.000000         151.000000\n"
     ]
    }
   ],
   "source": [
    "def print_triples_sizes(df):\n",
    "    df['claim_kg_size'] = df['claim_kg'].apply(lambda triples : len(triples))\n",
    "    df['main_text_kg_size'] = df['main_text_kg'].apply(lambda triples : len(triples))\n",
    "\n",
    "    print(df[['claim_kg_size', 'main_text_kg_size']].describe())\n",
    "    \n",
    "print_triples_sizes(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redundancy Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_triples(kg, clean=True):\n",
    "    triples = [f\"({triple['head']}, {triple['type']}, {triple['tail']})\" for triple in kg]\n",
    "\n",
    "    if clean:\n",
    "        n = len(triples)\n",
    "        sim_scores = get_similarity_scores_triples(triples)\n",
    "\n",
    "        to_drop = np.zeros(n, dtype=bool)\n",
    "\n",
    "        for i in range(n):\n",
    "            # Skip sentences that have already been marked for dropping\n",
    "            if to_drop[i]:\n",
    "                continue\n",
    "\n",
    "            for j in range(i + 1, n):\n",
    "                # If the similarity score between sentences i and j is above the threshold, mark one of them for dropping\n",
    "                if sim_scores[i, j] >= 0.9:\n",
    "                    to_drop[i] = True\n",
    "                    break\n",
    "\n",
    "        # Return the indices of sentences that are not marked for dropping\n",
    "        clean_triples = [triples[i] for i in range(n) if not to_drop[i]]\n",
    "        return clean_triples\n",
    "    else:\n",
    "        return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['claim_triples'] = data_df['claim_kg'].apply(lambda kg: get_cleaned_triples(kg, clean=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['clean_claim_triples'] = data_df['claim_kg'].apply(lambda kg: get_cleaned_triples(kg, clean=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2452.000000\n",
       "mean        3.113785\n",
       "std         0.534892\n",
       "min         1.000000\n",
       "25%         3.000000\n",
       "50%         3.000000\n",
       "75%         3.000000\n",
       "max         9.000000\n",
       "Name: claim_triples, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['claim_triples'].apply(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2452.000000\n",
       "mean        2.207178\n",
       "std         0.777266\n",
       "min         1.000000\n",
       "25%         2.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max         8.000000\n",
       "Name: clean_claim_triples, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['clean_claim_triples'].apply(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_pickle('dev_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['main_text_triples'] = data_df['main_text_kg'].apply(lambda kg: get_cleaned_triples(kg, clean=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['clean_main_text_triples'] = data_df['main_text_kg'].apply(lambda kg: get_cleaned_triples(kg, clean=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_pickle('./data/data_post_redundancy_removal.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>date_published</th>\n",
       "      <th>explanation</th>\n",
       "      <th>fact_checkers</th>\n",
       "      <th>main_text</th>\n",
       "      <th>sources</th>\n",
       "      <th>label</th>\n",
       "      <th>subjects</th>\n",
       "      <th>claim_kg</th>\n",
       "      <th>main_text_kg</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>claim_kg_size</th>\n",
       "      <th>main_text_kg_size</th>\n",
       "      <th>claim_triples</th>\n",
       "      <th>clean_claim_triples</th>\n",
       "      <th>main_text_triples</th>\n",
       "      <th>clean_main_text_triples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34656</td>\n",
       "      <td>A baby died at an unnamed medical facility be...</td>\n",
       "      <td>November 10, 2015</td>\n",
       "      <td>Fellow Twitter users suggested @FierceFemtivis...</td>\n",
       "      <td>Kim LaCapria</td>\n",
       "      <td>On 8 November 2015, former Twitter user @Fierc...</td>\n",
       "      <td>http://webcache.googleusercontent.com/search?q...</td>\n",
       "      <td>unproven</td>\n",
       "      <td>Politics, fiercefemtivist, racism</td>\n",
       "      <td>[{'head': 'A baby died at an unnamed medical f...</td>\n",
       "      <td>[{'head': 'Confederate flag', 'type': 'instanc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>[(A baby died at an unnamed medical facility, ...</td>\n",
       "      <td>[(A baby died at an unnamed medical facility, ...</td>\n",
       "      <td>[(Confederate flag, instance of, racist), (Fie...</td>\n",
       "      <td>[(Confederate flag, instance of, racist), (Fie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3632</td>\n",
       "      <td>Bat from Shawnee County tests positive for rab...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A bat found in northeastern Kansas has tested ...</td>\n",
       "      <td></td>\n",
       "      <td>Topeka television station KSNT reports that th...</td>\n",
       "      <td>https://www.ksnt.com/news/bat-tests-positive-f...</td>\n",
       "      <td>true</td>\n",
       "      <td>Rabies, Health, General News, Kansas, Bats, To...</td>\n",
       "      <td>[{'head': 'Bat from Shawnee County', 'type': '...</td>\n",
       "      <td>[{'head': 'KSNT', 'type': 'located in the admi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[(Bat from Shawnee County, has cause, rabies),...</td>\n",
       "      <td>[(Shawnee County, located in the administrativ...</td>\n",
       "      <td>[(KSNT, located in the administrative territor...</td>\n",
       "      <td>[(KSNT, located in the administrative territor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29558</td>\n",
       "      <td>Germany has banned pork from school canteens b...</td>\n",
       "      <td>March 7, 2016</td>\n",
       "      <td>What's true: Some politicians complained that ...</td>\n",
       "      <td>Kim LaCapria</td>\n",
       "      <td>On 7 March 2016, British tabloid Express repor...</td>\n",
       "      <td>http://bnp.org.uk/news/regional/bnp-victory-br...</td>\n",
       "      <td>false</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[{'head': 'banned pork from school canteens', ...</td>\n",
       "      <td>[{'head': 'Express', 'type': 'country', 'tail'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>[(banned pork from school canteens, country, G...</td>\n",
       "      <td>[(banned pork from school canteens, country, G...</td>\n",
       "      <td>[(Express, country, British), (Express, instan...</td>\n",
       "      <td>[(Express, country, British), (Express, instan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8416</td>\n",
       "      <td>Coronavirus prompts Canada to roll out safe dr...</td>\n",
       "      <td>April 16, 2020</td>\n",
       "      <td>Canada’s Pacific province of British Columbia ...</td>\n",
       "      <td>Tessa Vikander</td>\n",
       "      <td>In March, the Canadian government urged provin...</td>\n",
       "      <td></td>\n",
       "      <td>true</td>\n",
       "      <td>Health News</td>\n",
       "      <td>[{'head': 'Coronavirus', 'type': 'country', 't...</td>\n",
       "      <td>[{'head': 'heroin', 'type': 'instance of', 'ta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>[(Coronavirus, country, Canada), (safe drug, c...</td>\n",
       "      <td>[(Coronavirus, country, Canada), (safe drugs, ...</td>\n",
       "      <td>[(heroin, instance of, controlled substances),...</td>\n",
       "      <td>[(heroin, instance of, controlled substance), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7169</td>\n",
       "      <td>Wayne National Forest plans fires for tree, wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nearly 2,000 acres of Wayne National Forest in...</td>\n",
       "      <td></td>\n",
       "      <td>Forest officials say scientists who study nati...</td>\n",
       "      <td></td>\n",
       "      <td>true</td>\n",
       "      <td>Plants, Wildlife, Health, Wildlife health, For...</td>\n",
       "      <td>[{'head': 'Wayne National Forest', 'type': 'in...</td>\n",
       "      <td>[{'head': 'oak forests', 'type': 'located in t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[(Wayne National Forest, instance of, forest),...</td>\n",
       "      <td>[(Wayne National Forest, instance of, wildlife...</td>\n",
       "      <td>[(oak forests, located in the administrative t...</td>\n",
       "      <td>[(oak forests, located in the administrative t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  claim_id                                              claim  \\\n",
       "0    34656   A baby died at an unnamed medical facility be...   \n",
       "1     3632  Bat from Shawnee County tests positive for rab...   \n",
       "2    29558  Germany has banned pork from school canteens b...   \n",
       "3     8416  Coronavirus prompts Canada to roll out safe dr...   \n",
       "4     7169  Wayne National Forest plans fires for tree, wi...   \n",
       "\n",
       "      date_published                                        explanation  \\\n",
       "0  November 10, 2015  Fellow Twitter users suggested @FierceFemtivis...   \n",
       "1                NaN  A bat found in northeastern Kansas has tested ...   \n",
       "2      March 7, 2016  What's true: Some politicians complained that ...   \n",
       "3     April 16, 2020  Canada’s Pacific province of British Columbia ...   \n",
       "4                NaN  Nearly 2,000 acres of Wayne National Forest in...   \n",
       "\n",
       "    fact_checkers                                          main_text  \\\n",
       "0    Kim LaCapria  On 8 November 2015, former Twitter user @Fierc...   \n",
       "1                  Topeka television station KSNT reports that th...   \n",
       "2    Kim LaCapria  On 7 March 2016, British tabloid Express repor...   \n",
       "3  Tessa Vikander  In March, the Canadian government urged provin...   \n",
       "4                  Forest officials say scientists who study nati...   \n",
       "\n",
       "                                             sources     label  \\\n",
       "0  http://webcache.googleusercontent.com/search?q...  unproven   \n",
       "1  https://www.ksnt.com/news/bat-tests-positive-f...      true   \n",
       "2  http://bnp.org.uk/news/regional/bnp-victory-br...     false   \n",
       "3                                                         true   \n",
       "4                                                         true   \n",
       "\n",
       "                                            subjects  \\\n",
       "0                  Politics, fiercefemtivist, racism   \n",
       "1  Rabies, Health, General News, Kansas, Bats, To...   \n",
       "2                                           Politics   \n",
       "3                                        Health News   \n",
       "4  Plants, Wildlife, Health, Wildlife health, For...   \n",
       "\n",
       "                                            claim_kg  \\\n",
       "0  [{'head': 'A baby died at an unnamed medical f...   \n",
       "1  [{'head': 'Bat from Shawnee County', 'type': '...   \n",
       "2  [{'head': 'banned pork from school canteens', ...   \n",
       "3  [{'head': 'Coronavirus', 'type': 'country', 't...   \n",
       "4  [{'head': 'Wayne National Forest', 'type': 'in...   \n",
       "\n",
       "                                        main_text_kg  Unnamed: 0  \\\n",
       "0  [{'head': 'Confederate flag', 'type': 'instanc...         NaN   \n",
       "1  [{'head': 'KSNT', 'type': 'located in the admi...         NaN   \n",
       "2  [{'head': 'Express', 'type': 'country', 'tail'...         NaN   \n",
       "3  [{'head': 'heroin', 'type': 'instance of', 'ta...         NaN   \n",
       "4  [{'head': 'oak forests', 'type': 'located in t...         NaN   \n",
       "\n",
       "   claim_kg_size  main_text_kg_size  \\\n",
       "0              3                 14   \n",
       "1              3                  6   \n",
       "2              3                 36   \n",
       "3              3                 21   \n",
       "4              3                  3   \n",
       "\n",
       "                                       claim_triples  \\\n",
       "0  [(A baby died at an unnamed medical facility, ...   \n",
       "1  [(Bat from Shawnee County, has cause, rabies),...   \n",
       "2  [(banned pork from school canteens, country, G...   \n",
       "3  [(Coronavirus, country, Canada), (safe drug, c...   \n",
       "4  [(Wayne National Forest, instance of, forest),...   \n",
       "\n",
       "                                 clean_claim_triples  \\\n",
       "0  [(A baby died at an unnamed medical facility, ...   \n",
       "1  [(Shawnee County, located in the administrativ...   \n",
       "2  [(banned pork from school canteens, country, G...   \n",
       "3  [(Coronavirus, country, Canada), (safe drugs, ...   \n",
       "4  [(Wayne National Forest, instance of, wildlife...   \n",
       "\n",
       "                                   main_text_triples  \\\n",
       "0  [(Confederate flag, instance of, racist), (Fie...   \n",
       "1  [(KSNT, located in the administrative territor...   \n",
       "2  [(Express, country, British), (Express, instan...   \n",
       "3  [(heroin, instance of, controlled substances),...   \n",
       "4  [(oak forests, located in the administrative t...   \n",
       "\n",
       "                             clean_main_text_triples  \n",
       "0  [(Confederate flag, instance of, racist), (Fie...  \n",
       "1  [(KSNT, located in the administrative territor...  \n",
       "2  [(Express, country, British), (Express, instan...  \n",
       "3  [(heroin, instance of, controlled substance), ...  \n",
       "4  [(oak forests, located in the administrative t...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evidence Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_most_related_evidence(row, k, cleaned=True):\n",
    "\n",
    "    if cleaned:\n",
    "        claim_triples = row['clean_claim_triples']\n",
    "        evidence_triples = row['clean_main_text_triples']\n",
    "    else:\n",
    "        claim_triples = row['claim_triples']\n",
    "        evidence_triples = row['main_text_triples']\n",
    "\n",
    "    relevant_claim_evidence_pairs = {}\n",
    "    for claim_triple in claim_triples:\n",
    "        topk_evidences = get_topk_similar_evidences(claim_triple, evidence_triples, k)\n",
    "        relevant_claim_evidence_pairs[claim_triple] = topk_evidences\n",
    "\n",
    "    if row.name%100 == 0:\n",
    "        print(row.name)\n",
    "\n",
    "    return relevant_claim_evidence_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "data_df['cleaned_claim_evidence_1'] = data_df.apply(lambda row: pair_most_related_evidence(row, 1, cleaned=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "data_df['claim_evidence_1'] = data_df.apply(lambda row: pair_most_related_evidence(row, 1, cleaned=False), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_pickle('./data/data_post_evidence_retrieval.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entailment_scores(row, cleaned=True):\n",
    "    if cleaned:\n",
    "        claim_evidences = row['cleaned_claim_evidence_1']\n",
    "    else:\n",
    "        claim_evidences = row['claim_evidence_1']\n",
    "\n",
    "    evidence_claim_tuples = []\n",
    "    for claim, evidences in claim_evidences.items():\n",
    "        evidence_claim_tuples.append((evidences[0], claim))\n",
    "\n",
    "    if row.name%100==0:\n",
    "        print(row.name)\n",
    "\n",
    "    return get_entailment(evidence_claim_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "data_df['cleaned_entailment_scores_1'] = data_df.apply(lambda row : get_entailment_scores(row, cleaned=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "data_df['entailment_scores_1'] = data_df.apply(lambda row : get_entailment_scores(row, cleaned=False), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_pickle('./data/data_post_entailment.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
